{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "solving-quora-question-pair.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vikas-KM/quora-question-pair/blob/main/solving_quora_question_pair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "n_cvjfRnmOv9"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YZIcHR1JmOwG"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "ukPqpvxBmOwI"
      },
      "source": [
        "zf = zipfile.ZipFile('/kaggle/input/quora-question-pairs/train.csv.zip')\n",
        "df_train = pd.read_csv(zf.open('train.csv'))\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyz66jsBmOwK"
      },
      "source": [
        "### Examples of duplicate examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zAkxrjJimOwL"
      },
      "source": [
        "# change the index of iloc to see different questions to get and idea\n",
        "df1 = df_train[df_train['is_duplicate'] == 0]\n",
        "df2 = df_train[df_train['is_duplicate'] == 1]\n",
        "\n",
        "qstn1 = df1.iloc[0]['question1']\n",
        "qstn2 = df1.iloc[0]['question2']\n",
        "is_dup1 = df1.iloc[0]['is_duplicate']\n",
        "\n",
        "qstn3 = df2.iloc[0]['question1']\n",
        "qstn4 = df2.iloc[0]['question2']\n",
        "is_dup2 = df2.iloc[0]['is_duplicate']\n",
        "\n",
        "\n",
        "print(qstn1)\n",
        "print(qstn2)\n",
        "print('are they duplicates? ', is_dup1)\n",
        "\n",
        "print(qstn3)\n",
        "print(qstn4)\n",
        "print('are they duplicates? ', is_dup2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoZ9PfGJmOwM"
      },
      "source": [
        "## basic analysis on the train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FbFENkcomOwN"
      },
      "source": [
        "# how many data points\n",
        "df_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VU6AXZZRmOwP"
      },
      "source": [
        "# names of the columns\n",
        "df_train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kIJIOen6mOwP"
      },
      "source": [
        "# how is data spread, finding the balance/imbalance of the data\n",
        "df_train['is_duplicate'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "e9wI9pO5mOwQ"
      },
      "source": [
        "# any null values present\n",
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qw2aMeHkmOwS"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Doq29yImmOwT"
      },
      "source": [
        "print('{}% of duplicate pairs of question'.format(round(df_train['is_duplicate'].mean()*100,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jsBZUowmOwV"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "w0GlJIVfmOwW"
      },
      "source": [
        "# count of duplicate and not duplicate questions\n",
        "df_train.groupby('is_duplicate')['id'].count().plot.bar()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FmcVgaumOwX"
      },
      "source": [
        "### references\n",
        "- https://datatofish.com/convert-pandas-dataframe-to-list/\n",
        "- https://queirozf.com/entries/pandas-dataframe-examples-duplicated-data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VKQnZzHpmOwY"
      },
      "source": [
        "df_train['qid1'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "t8DYQO79mOwY"
      },
      "source": [
        "df_train['qid2'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmu7PvVTmOwZ"
      },
      "source": [
        "### Observations\n",
        "- Some qids are repeated, that means few questions are repeating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "f7c0nLvPmOwZ"
      },
      "source": [
        "# number of unique questions\n",
        "qids = pd.Series(df_train['qid1'].tolist() + df_train['qid2'].tolist())\n",
        "total_qstns = len(qids)\n",
        "unique_qstns = len(np.unique(qids))\n",
        "repeated_qstns = np.sum(qids.value_counts() >1)\n",
        "print('Total number of questions ',total_qstns)\n",
        "print('Total number of uniques questions ',unique_qstns)\n",
        "print('Total number of repeated questions',repeated_qstns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HCIYHxm0mOwa"
      },
      "source": [
        "x=['unique questions', 'repeated questions']\n",
        "y=[unique_qstns, repeated_qstns]\n",
        "sns.barplot(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tD7pzMuumOwa"
      },
      "source": [
        "# how many times questions are repeated max?\n",
        "qids.value_counts().iloc[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EXvy7dIWmOwa"
      },
      "source": [
        "# questions are in huge numbers so taking logscale for y axis\n",
        "# nonposy=clip mean negative of log not defined so here a small value is taken\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.hist(qids.value_counts(), bins=120)\n",
        "plt.yscale('log', nonposy='clip')\n",
        "plt.title('Log-Histogram of question appearance counts')\n",
        "plt.xlabel('Number of occurences of question')\n",
        "plt.ylabel('Number of questions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9UCX8pOmOwb"
      },
      "source": [
        "### Observations\n",
        "- As from the above plot we can see, there is a question that is repeated 157, 120, 111 times\n",
        "( see the above plot query for 157 number)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "l8VaqXkKmOwb"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mLjcDu0JmOwb"
      },
      "source": [
        "# finding rows that have NaN values\n",
        "df_train[df_train.isna().any(1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62s9OgaRmOwb"
      },
      "source": [
        "### Observations\n",
        "- There are 3 rows which have NaN value\n",
        "    - we can delete those rows\n",
        "    - we can fill them with a empty string\n",
        "    \n",
        "   \n",
        "Since the NaN value are only 3 we will discard/drop them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkOjADiUmOwc"
      },
      "source": [
        "### references\n",
        "- https://stackoverflow.com/questions/13851535/how-to-delete-rows-from-a-pandas-dataframe-based-on-a-conditional-expression\n",
        "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uZHvUvmumOwc"
      },
      "source": [
        "# droping the NaN values\n",
        "df_train.dropna(axis=0, how='any', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "G7KcbVE4mOwc"
      },
      "source": [
        "df_train[df_train.isna().any(1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8oANgoZtmOwc"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3YfnOpfTmOwd"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VWkzS4MWmOwd"
      },
      "source": [
        "## Checking if any pair is duplicate\n",
        "dup = df_train[['qid1','qid2','is_duplicate']].groupby(['qid1','qid2']).count().reset_index()\n",
        "df_train.shape[0] - dup.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRG6q0rCmOwe"
      },
      "source": [
        "### Naive Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "H-pck7AVmOwe"
      },
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "p = df_train['is_duplicate'].mean() # Our predicted probability\n",
        "print('Predicted score:', log_loss(df_train['is_duplicate'], np.zeros_like(df_train['is_duplicate']) + p))\n",
        "\n",
        "# zf = zipfile.ZipFile('/kaggle/input/quora-question-pairs/test.csv.zip')\n",
        "# df_test = pd.read_csv(zf.open('test.csv'))\n",
        "\n",
        "df_test = pd.read_csv('/kaggle/input/quora-question-pairs/test.csv')\n",
        "sub = pd.DataFrame({'test_id': df_test['test_id'], 'is_duplicate': p})\n",
        "sub.to_csv('naive_submission.csv', index=False)\n",
        "sub.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qLzaJsnjmOwf"
      },
      "source": [
        "df = pd.read_csv('./naive_submission.csv')\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2cemkUHmOwf"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKdFIPD6mOwf"
      },
      "source": [
        "### Lets create a few new Features\n",
        "- **freq_qid1, freq_qid2** -> Frequency count of the qids\n",
        "- **qlen1, qlen2** -> Length of the question\n",
        "\n",
        "- **q1_words, q2_words** -> Number of words in the question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JkGj4EhMmOwg"
      },
      "source": [
        "# copying the df_train to df\n",
        "df = df_train.copy()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKBiiGntmOwg"
      },
      "source": [
        "### References\n",
        "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transform.html\n",
        "- https://pbpython.com/pandas_transform.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XM1pPbKkmOwg"
      },
      "source": [
        "# using pandas transform to count the frequency of the qstn based on qid\n",
        "df['freq_qid1'] = df.groupby('qid1')['qid1'].transform('count')\n",
        "df['freq_qid2'] = df.groupby('qid2')['qid2'].transform('count')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b2VVR0dRmOwh"
      },
      "source": [
        "# finding the length of the qstn and creating a new feature\n",
        "df['qlen1'] = df['question1'].apply(lambda x:len(x))\n",
        "df['qlen2'] = df['question2'].apply(lambda x:len(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UFwy7QqZmOwh"
      },
      "source": [
        "# number of words in the questions\n",
        "df['q1_words'] = df['question1'].apply(lambda x: len(x.split(' ')))\n",
        "df['q2_words'] = df['question2'].apply(lambda x: len(x.split(' ')))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5lQV3g_mOwi"
      },
      "source": [
        "### References\n",
        "- https://stackoverflow.com/questions/11938964/how-to-find-common-words-and-print-them-using-python-command/12136296\n",
        "\n",
        "    - common = set(document_1_words).intersection( set(document_2_words) )\n",
        "    - unique = set(document_1_words).symmetric_difference( set(document_2_words) )\n",
        "    \n",
        "    \n",
        "- **common_words** -> common words to question1 and question2\n",
        "- **total_words** -> total unique words to belonging to both question1 and question2\n",
        "- **share_words** -> the share words is defined as common words divided by total words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Dv9a0GUnmOwi"
      },
      "source": [
        "# common words to both qstn1 and qstn2 \n",
        "def word_common(row):\n",
        "        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
        "        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n",
        "        return len(w1.intersection(w2))\n",
        "df['common_words'] = df.apply(word_common, axis=1)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cS7j3O9FmOwi"
      },
      "source": [
        "# Total words of both qstn1 and qstn2 \n",
        "def word_total(row):\n",
        "        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
        "        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n",
        "        return len(w1)+len(w2)\n",
        "df['total_words'] = df.apply(word_total, axis=1)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9tZK4er9mOwj"
      },
      "source": [
        "# words shared between of both qstn1 and qstn2 \n",
        "# gives us an idea as to how similar the two qstns maybe\n",
        "# higher the share words implies more similar the wordings are of the two sentences\n",
        "\n",
        "df['share_words'] = df['common_words']/(df['total_words'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra4EJWxkmOwj"
      },
      "source": [
        "### Analysis from the extracted features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dT2SMnDMmOwj"
      },
      "source": [
        "# minimum length of the question1\n",
        "print('minimum length of the qstn1 is ',min(df['qlen1']))\n",
        "\n",
        "# minimum length of the question2\n",
        "print('minimum length of the qstn2 is ',min(df['qlen2']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NArZrkTKmOwj"
      },
      "source": [
        "# questions of minimum length\n",
        "print(df[df['qlen1']== 1].shape[0])\n",
        "df[df['qlen1']== 1]['question1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "l6KTw5RymOwk"
      },
      "source": [
        "print(df[df['qlen2']== 1].shape[0])\n",
        "df[df['qlen2']== 1]['question2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gzbJ_gdwmOwk"
      },
      "source": [
        "df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGbo6bjbmOwk"
      },
      "source": [
        "### Observation\n",
        "- There are 19 questions of Question1 which has only 1 character\n",
        "- There are 2 questions of Question2 which has only 1 character\n",
        "\n",
        "These 21 form a miniscule part(0.005%) of the training, we can drop them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YlHDyd9DmOwk"
      },
      "source": [
        "min(df['q1_words'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "02tO-yP1mOwl"
      },
      "source": [
        "print(df[df['q1_words']== 1].shape[0])\n",
        "df[df['q1_words']== 1]['question1']\n",
        "print(df[df['q1_words']== 1]['question1'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XU0X112_mOwl"
      },
      "source": [
        "min(df['q2_words'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5y8lrfPymOwl"
      },
      "source": [
        "print(df[df['q2_words']== 1].shape[0])\n",
        "df[df['q2_words']== 1]['question2']\n",
        "print(df[df['q2_words']== 1]['question2'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iYBDkWrbmOwl"
      },
      "source": [
        "df[df['question2']=='Spam']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y4NJvbbPmOwl"
      },
      "source": [
        "df[df['question2']=='deleted']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0N2QjthmOwl"
      },
      "source": [
        "### Observations\n",
        "- There are 66 and 22 question with one word in question1 and Question2\n",
        "- bunch of keywords are deleted/delete spam and lol and dots conveying nothing at all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zdLtra4emOwm"
      },
      "source": [
        "df['share_words'][0:].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IWuN5fbmOwm"
      },
      "source": [
        "##### Can the share_words be used to see if it will help to separate the given question pairs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lbHrOZQHmOwm"
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.distplot(df[df['is_duplicate'] == 1.0]['share_words'], label = \"is_duplicate\", color = 'green')\n",
        "sns.distplot(df[df['is_duplicate'] == 0.0]['share_words'], label = \"not_duplicate\" , color = 'blue' )\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91nX0JptmOwn"
      },
      "source": [
        "### Observation\n",
        "- green indicates duplicates, higher share words means they may be duplicates\n",
        "- blue indicates not duplicates, lower share words means they may not be duplicates\n",
        "\n",
        "Since there is lot of overlap it is not strict separation as can be seen from the above graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vuDINMAZmOwn"
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "x = df['is_duplicate']\n",
        "y = df['share_words']\n",
        "sns.violinplot(x,y, hue=df['is_duplicate'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJPoedHwmOwn"
      },
      "source": [
        "##### Can the common_words be used to see if it will help to separate the given question pairs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Yj3g3Br_mOwn"
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.distplot(df[df['is_duplicate'] == 1.0]['common_words'], label = \"is_duplicate\", color = 'green')\n",
        "sns.distplot(df[df['is_duplicate'] == 0.0]['common_words'], label = \"not_duplicate\" , color = 'blue' )\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLvCdWNzmOwn"
      },
      "source": [
        "#### Observation:\n",
        "- too much overlap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oaT3JwnmOwo"
      },
      "source": [
        "## Text Preprocessing\n",
        "\n",
        "- Removing HTML Tags\n",
        "- Removing Punctuations\n",
        "- Removing Numbers\n",
        "- Performing Stemming\n",
        "- Removing Stop words etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Fvg9iI2JmOwo"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQyeSUPjmOwo"
      },
      "source": [
        "#### Code to remove URL links from text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zwQIQkGamOwo"
      },
      "source": [
        "# https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python/40823105#40823105\n",
        "def remove_URL(text):\n",
        "    \"\"\"Remove URLs from a text string\"\"\"\n",
        "    return re.sub(r\"http\\S+\", \"\", text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AmElWKPMmOwp"
      },
      "source": [
        "df['question1'] = df['question1'].apply(lambda x: remove_URL(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ohautqNimOwp"
      },
      "source": [
        "df['question2'] = df['question2'].apply(lambda x: remove_URL(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BpHqdkeSmOwp"
      },
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv_jSQQumOwp"
      },
      "source": [
        "#### Code to remove tags using beautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GMGPtl9tmOwp"
      },
      "source": [
        "# https://stackoverflow.com/questions/16206380/python-beautifulsoup-how-to-remove-all-tags-from-an-element\n",
        "def getText(x):\n",
        "    soup = BeautifulSoup(x, 'lxml')\n",
        "    text = soup.get_text()\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UWvT4xGpmOwp"
      },
      "source": [
        "df['question1'] = df['question1'].apply(lambda x: getText(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hlZLplmAmOwq"
      },
      "source": [
        "df['question2'] = df['question2'].apply(lambda x: getText(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PG_KXDamOwq"
      },
      "source": [
        "#### Expanding English language contractions in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uvGcdpq-mOwq"
      },
      "source": [
        "! pip install contractions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bDkKWKq_mOwq"
      },
      "source": [
        "import contractions\n",
        "print(contractions.fix(\"you've\"))\n",
        "print(contractions.fix(\"he's\"))\n",
        "print(contractions.fix(\"'ll\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cW4o_AL8mOwq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1aUOXGiNmOwr"
      },
      "source": [
        "#https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0gLdE4WQmOwr"
      },
      "source": [
        "# removing special characters\n",
        "def remove_spl(x):\n",
        "    x = re.sub('[^A-Za-z0-9]+', '', x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fCgxRE0YmOwr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qRt0ko3xmOwr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "M_Rnt2C-mOwr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MYcJ6tCsmOwr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSUN_IcImOws"
      },
      "source": [
        "### References:\n",
        "- https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb/notebook"
      ]
    }
  ]
}